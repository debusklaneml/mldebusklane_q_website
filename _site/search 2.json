[
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "Morgan ‘Les’ DeBusk-Lane, Ph.D.",
    "section": "",
    "text": "Morgan ‘Les’ DeBusk-Lane, Ph.D.\nEmail: mldebusklane@gmail.com\nCrafted: Apr 2024\n\n\n\nEducation\n\nDoctor of Philosophy (Educational Psychology), Virginia Commonwealth University: Advisor: Dr. Sharon Zumbrunn\nBachelor of Science in Psychology, Pennsylvania State University - with High Distinction.\n\n\n\n\nPeer Reviewed Articles\n(alphabetical)\n\nBae, C. & DeBusk-Lane, M. (2019). Middle school engagement: Implications for motivation and achievement in science. Learning and Individual Differences, 74, https://doi.org/10.1016/j.lindif.2019.101753\n\n\nBae, C. & DeBusk-Lane, M. (2018). Stability of motivation belief profiles in science: Links to classroom goal structures and achievement. Learning and Individual Differences, 67, 91-104. https://doi.org/10.1016/j.lindif.2018.08.003\n\n\nBae, C., DeBusk-Lane, M., Hayes, K. & Zhang, F. (2018). Opportunities to participate (OtP) in science: Examining differences longitudinally and across socioeconomically diverse schools. Research in Science Education, 1-22. https://doi.org/10.1007/s11165-018-9797-5\n\n\nBae, C., Hayes, K., DeBusk-Lane, M. (2020). Profiles of middle school science teachers: Accounting for cognitive and motivational characteristics. Journal of Research in Science Teaching, 57(6), 911-942.\n\n\nBae, C. L., DeBusk-Lane, M., & Lester, A. M. (2020). Engagement profiles of elementary students in urban schools. Contemporary Educational Psychology, 62, 101880. https://doi.org/10.1016/j.cedpsych.2020.101880\n\n\nCabrera, L., Bae, C., DeBusk-Lane, M. (2023). A mixed methods study of middle students’ science motivation and engagement profiles. Learning and Individual Differences, 103, https://doi.org/ 10.1016/j.lindif.2023.102281\n\n\nDeBusk-Lane, M., Zumbrunn, S., Bae, C., Broda, M., Bruning, R., & Sjogren, A. (2023). Variable- and Person-Centered Approaches to Examining Construct-Relevant Multidimensionality in Writing Self-Efficacy. Frontiers in Psychology, 14, https://doi.org/10.3389/fpsyg.2023.1091894\n\n\nEkholm, E., Zumbrunn, S., & DeBusk-Lane, M. (2017). Clarifying an elusive construct: A systematic review of writing attitudes. Educational Psychology Review, 30(3), 827-856. https://doi.org/10.1007/s10648-017-9423-5\n\n\nMaese, E., Diego-Rosell, P., Debusk-Lane, L., & Kress, N. (2021, November). Development of emergent leadership measurement: Implications for human-machine teams. In AAAI Fall Symposium (pp. 118-145). Cham: Springer Nature Switzerland.\n\n\nRedifer, J., Bae, C., & DeBusk-Lane, M. (2019). Implicit Theories, Working Memory, and Cognitive Load: Impacts on Creative Thinking. SAGE Open, 9(1), 1-16. https://doi.org/10.1177/2158244019835919\n\n\nZumbrunn, S., Ekholm, E., Stringer, J. K., McKnight, K., & DeBusk-Lane, M. (2017). Student Experiences With Writing: Taking the Temperature of the Classroom. The Reading Teacher, 70(6), 667–677. https://doi.org/10.1002/trtr.1574\n\n\nZumbrunn, S., Marrs, S., Broda, M., Ekholm, E., DeBusk-Lane, M., Jackson, L. (2019). Toward a more complete understanding of elementary writing attitudes: A mixed methods study of elementary students. AERA Open, 5(2), 1-16.\n\n\n\n\nPeer Reviewed Presentations\n(alphabetical)\n\nDeBusk-Lane, M., Bae, C., & Lester, A. Student engagement in urban elementary schools: A Variable- and person-centered approach (Paper presented at the 2020 American Educational Research Association in San Fransisco, CA.)\n\n\nBae, C. & DeBusk-Lane, M., Engaging Students in Science: Measurement Invariance of Science Practices across Middle School Grades and Socioeconomic Subgroups (Paper presented at the 2017 Society for Research on Educational Effectiveness: SREE)\n\n\nBae, C., DeBusk-Lane, M., & Hayes, K., Student Engagement in Middle School Science: Findings across socioeconomic subgroups (Poster presented at the 2017 American Psychological Association in Washington, D.C.)\n\n\nBae, C., DeBusk-Lane, M., & Hayes, K., Student Engagement in Middle School Science: Findings across socioeconomic subgroups (Paper presented at the 2018 American Educational Research Association in New York, NY.)\n\n\nBae, C., DeBusk-Lane, M. Profiles of motivation in middle school science: Links to classroom structures and achievement (Poster presented at the 2018 American Psychological Association in San Francisco, CA.)\n\n\nDeBusk-Lane, M. & Bae, C., Students’ Engagement in Middle School Science: Measurement Invariance and Group Mean Comparisons Across Language Subgroups. (Poster presented at the 2017 Association for Psychological Science Convention, Boston, MA.)\n\n\nDeBusk-Lane, M., Gnilka, P., Bae, C., Akcil, S., & Fee, H. Counselor Burnout Inventory: Factor Structure and Measurement Invariance across U.S. and Turkish Professional School Counselors. (Paper presented at the 2018 American Educational Research Association, New York, NY.)\n\n\nDeBusk-Lane, M., Lester, A., Zumbrunn, S. Understanding Profiles of Writing Self-Efficacy through Mixed Methods Analysis. (Poster presented at the 2018 American Educational Research Association, New York, NY.)\n\n\nEkholm, E., Zumbrunn, S., & DeBusk-Lane, M., Clarifying an elusive construct: A systematic review of writing attitudes. (Paper presented at the 2017 American Educational Research Association, San Antonio, TX.)\n\n\nGnilka, P., DeBusk-Lane, M., Moate, R., Rice, K., Ashby, J., & Zumbrunn, S., Perfectionism and the HEXACO Model of Personality. (Paper presented at the 2017 Association for Psychological Science, Boston, MA.)\n\n\nJackson, L., DeBusk-Lane, M., Zumbrunn, S., & Baker, A., A Qualitative Study on the Collective Efficacy and Belongingness of Undergraduate Students (Paper presented at the 2016 American Psychological Association convention, Denver, CO.)\n\n\nLester, A. M., Chow, J., & DeBusk-Lane, M. Adolescent Participation in Afterschool Programs: A Systematic Review and Meta-analysis. (Poster presented at the 2018 American Psychological Association, San Fransisco, CA.)\n\n\nLester, A., DeBusk-Lane, M., Ekholm, E., Kunemund, R., Sterrett, B., Hope, S., … Zumbrunn, S.. Making schools more inclusive, inviting, and supportive: A community perspective. (Poster presented at Virginia Commonwealth University’s 2017 Racial Disproportionality, School Discipline, and Future Directions symposium.)\n\n\nLester, A., DeBusk-Lane, M., & Siegel-Hawley, G.. Investigating profiles of school level demographic change in relation to racial disproportionality in discipline. (Paper presented at the 2019 American Educational Research Association, Toronto, Canada)\n\n\nLester, A. M., DeBusk-Lane, M., & Zumbrunn, S. Investigating Profiles of Students’ Writing Self-Efficacy: A Mixed Methods Approach. (Poster presented at the 2018 American Psychological Association, San Fransisco, CA.)\n\n\nLove, S., Rufer, L., DeBusk-Lane, M., & Zumbrunn, S., Exploring Student Athlete Motivation in Academics and Athletics. (Paper presented at the 2016 American Psychological Association convention, Denver, CO.).\n\n\nMaese, E., Diego-Roosell, P., Srinivasan, R., Bikus, Z., DeBusk-Lane, M., Davoodi, T., Van Klinken, M., Foy, D., Food Insecurity in Context: Developing Mental Models of Local Knowledge in Halabja, Iraq. (Presentation to the American Public Health Association, 2022).\n\n\nMarrs, S. A., Zumbrunn, S. K., Jackson, L. O., Ekholm, E., DeBusk-Lane, M.. Exploring elementary students’ preferences for writing tasks. (Poster presented at the 2017 meeting of the American Psychological Association, Washington, D.C.)\n\n\nRedifer, J. Bae, C., & DeBusk-Lane, M., Cognitive Load Mediates the Relationship Between Implicit Beliefs and Creative Thinking Scores. (Poster presented at the 2017 Association for Psychological Science, Boston, MA.)\n\n\nSiegel-Hawley, G, DeBusk-Lane, M., Lester, A., Naff, D., & Palencia, V. Race, place, and exclusion: The metropolitan landscape of racial inequity in school discipline. (Paper presented at the 2019 American Educational Research Association, Toronto, Canada)\n\n\nSjogren, A., DeBusk-Lane, M., & Bae, C. Student engagement across contexts. (Symposium presented at the 2021 American Educational Research Association, Virtual Meeting).\n\n\nStringer, J., DeBusk-Lane, M., Zumbrunn, S., & Walsh, M., Academic self-concept: A qualitative approach. (Paper presented at the 2016 American Psychological Association convention, Denver, CO.).\n\n\nZumbrunn, S., Ekholm, E., Stringer, J., McKnight, K., & DeBusk-Lane, M., Exploring the experience of writing through student drawings. (Paper presented at the 2016 American Psychological Association convention, Denver, CO.).\n\n\nZumbrunn, S., Marrs, S., Jackson, L., Broda, M., Ekholm, E., & DeBusk-Lane, M., Student perceptions of teacher and peer enthusiasm for writing, writing attitudes, and writing self-regulation: A mixed methods study. (Paper presented at the meeting of the 2017 American Educational Research Association, San Antonio, TX.)\n\n\nZumbrunn, S., Marrs, S., Malmberg, L., Ekholm, E., Broda, M., & DeBusk-Lane, M., Individual differences and the development of multiple dimensions of writing self-efficacy. (Paper presented at the 2018 International Conference of the EARLI Special Interest Group on Writing, Antwerp, Belgium)\n\n\n\n\nPeer Reviewed Reports\n\nSiegel-Hawley, G., Tefera, A. A., Naff, D., Lester, A., Levy, R., Palencia, V., Parry, M., & DeBusk-Lane, M. (2019). Understanding racial inequities in school discipline across the Richmond region. Richmond, VA: Metropolitan Educational Research Consortium."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "M. L. DeBusk-Lane, Ph.D.",
    "section": "",
    "text": "Hi There!\nWelcome. This is a site that I’ve put together (with R) to help communicate (and store) many of the things I’m interested in, who I am, and what I do. Thanks for coming. All opinions my own.\n\n\nWho I am:\nI enjoy learning, using data to answer cool questions, and spending time with my family, friends, and dogs. I live in Richmond, Va.\n\n\nWhat I do:\nI am currently a Computational Social Scientist at Gallup where I get to answer cool questions with world data, use fancy statistics, and help build really cool partnerships across DOD, other government agencies, and the public sector."
  },
  {
    "objectID": "posts/simulation/simulation.html",
    "href": "posts/simulation/simulation.html",
    "title": "Simulation: Part 0",
    "section": "",
    "text": "Loading required package: pacman\n\n\nThis blog post will be the first in a series that will explore how social scientists, or at least those that tend to span across and into more traditional data science, can leverage and employ simulation techniques into their workflow. At the least, this series will introduce the reader to what statistical simulation is, the very basics, and how it can be used to better understand how a variety of statistical methods function across broad data situations.\n\nWhat is statistical simulation and why should you care?\nIn our case, it’s the process of making fake data in a programmatic way. Statistical simulation is a powerful tool that allows us to create and analyze data in a controlled environment. By simulating data, we can explore the behavior of statistical models under various conditions—conditions that may be rare or difficult to observe in the real world. This is particularly useful when working with complex models or when trying to understand the impact of different data characteristics on statistical inference.\nFor instance, if I wanted to understand how well a simple linear regression (OLS) functioned across different, often anticipated, data situations, I could simulate those situations (the data) and then compute how well it did.\nUsing that as a simple example, lets do just that:\n\\[\ny = \\beta_0 + x_1\\beta_1 + \\varepsilon\n\\] In its simplest form, some variable \\(x_1\\) is linearly related to \\(y\\) given some constant influence of \\(\\beta_1\\). Said another way,\n\nlibrary(tidyverse)\n\nset.seed(123) # For reproducibility\nn &lt;- 10000\nbeta_0 &lt;- 1.5\nbeta_1 &lt;- 2.0\nsigma &lt;- 1.0\n\nx_1 &lt;- rnorm(n, mean = 2.5, sd = 1.0)\nepsilon &lt;- rnorm(n, mean = 0, sd = sigma)\ny &lt;- beta_0 + beta_1 * x_1 + epsilon\n\nsimulated_data &lt;- tibble(x_1 = x_1, y = y)\n\nTo get a better sense of this relationship, it’s always great to visualize it.\n\nggplot(simulated_data, aes(x = x_1, y = y)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(intercept = beta_0, slope = beta_1, color = \"blue\", size = 1) +\n  theme_minimal() +\n  labs(title = \"Simulated Data for OLS\",\n       x = \"Independent Variable (x_1)\",\n       y = \"Dependent Variable (y)\")\n\n\n\n\n\n\n\n\nNow we can estimate a model.\n\nols_model &lt;- lm(y ~ x_1, data = simulated_data)\nsummary(ols_model)\n\n\nCall:\nlm(formula = y ~ x_1, data = simulated_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4826 -0.6689 -0.0074  0.6809  3.7696 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.47581    0.02698    54.7   &lt;2e-16 ***\nx_1          2.00604    0.01003   200.0   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.002 on 9998 degrees of freedom\nMultiple R-squared:    0.8, Adjusted R-squared:    0.8 \nF-statistic: 4e+04 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nGiven the model, we can now compare how well our model fits the conditions for which we simulated the data. Given the variability we weaved in, you can see that we approximate the parameters we established within the simulation function above.\n\n\nUtility of Simulation\nWe can adjust the simulation parameters to see how well any method, in this case OLS, handles new parameters that change how the data interacts.\n\nsigma_new &lt;- 2.0\nepsilon_new &lt;- rnorm(n, mean = 0, sd = sigma_new)\ny_new &lt;- beta_0 + beta_1 * x_1 + epsilon_new\n\nsimulated_data_new &lt;- tibble(x_1 = x_1, y = y_new)\nols_model_new &lt;- lm(y ~ x_1, data = simulated_data_new)\nsummary(ols_model_new)\n\n\nCall:\nlm(formula = y ~ x_1, data = simulated_data_new)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.9672 -1.3655 -0.0144  1.3816  8.7195 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.38569    0.05389   25.71   &lt;2e-16 ***\nx_1          2.04008    0.02003  101.83   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.001 on 9998 degrees of freedom\nMultiple R-squared:  0.5091,    Adjusted R-squared:  0.5091 \nF-statistic: 1.037e+04 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nIn this case, we can compare the models to see how well OLS handles an increase in error variance.\n\n\nNext Steps\nIn the next post, we’ll look at how we can simulation non-linear relationships. Stay tuned.\n\n\nPython Version\nIf you’re curious, this would be the python rendition\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Parameters\nn = 10000\nbeta_0 = 1.5\nbeta_1 = 2.0\nsigma = 1.0\n\n# Simulate independent variable x_1\nx_1 = np.random.normal(2.5, 1.0, n)\n# Simulate error term\nepsilon = np.random.normal(0, sigma, n)\n# Simulate dependent variable y\ny = beta_0 + beta_1 * x_1 + epsilon\n\n# Plot the simulated data and the true regression line\nplt.figure(figsize=(10, 6))\nplt.scatter(x_1, y, alpha=0.5, label='Simulated data')\nplt.plot(x_1, beta_0 + beta_1 * x_1, 'r', label='True regression line')\nplt.title('Simulated Data for OLS')\nplt.xlabel('Independent Variable (x_1)')\nplt.ylabel('Dependent Variable (y)')\nplt.legend()\nplt.show()\n\n# Add a constant to the independent variable to model the intercept\nx_1_with_const = sm.add_constant(x_1)\n\n# Fit OLS regression model\nmodel = sm.OLS(y, x_1_with_const)\nresults = model.fit()\n\n# Print out the statistics\nprint(results.summary())\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{l._debusk-lane2023,\n  author = {L. DeBusk-Lane, M.},\n  title = {Simulation: {Part} 0},\n  date = {2023-11-04},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nL. DeBusk-Lane, M. 2023. “Simulation: Part 0.” November 4,\n2023."
  },
  {
    "objectID": "posts/conformal/confromal.html",
    "href": "posts/conformal/confromal.html",
    "title": "Conformal Prediction",
    "section": "",
    "text": "# Description of file here\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(tidyverse, explore, tidylog, skimr, plotly, \n               performance, mgcv, quantregForest,\n               gridExtra)\n\nConformal prediction stands at the forefront of modern data analysis, offering a robust way to assess the reliability of predictive models. This technique is particularly valuable in scenarios where accurate and reliable predictions are crucial, such as in healthcare, finance, and various other business cases. In most real work cases, the error of any given model is not uniform or constant across the range of possible predictions. Therefore, it’s important to take this into account when using a model to predict.\nConformal prediction is notably non-parametric and distribution-free, meaning it is not constrained by the underlying distribution of your data. This characteristic lends it exceptional flexibility, making it applicable across various types of models. It is effective for both classification and regression problems, regardless of the specific model used.\nDespite aligning with the frequentist perspective in quantifying uncertainty, conformal prediction provides a robust guarantee regarding the error bounds. It ensures that these bounds will encompass the true outcome within a specified confidence level. This makes it a reliable tool for making predictions with quantifiable certainty.\nThis post will cover a few different ways to compute prediction intervals.\n\nData Simulation:\nLets start by generating data often found in the real world. These data will produce a probability that ranges from 0 to 1. This will let me flip this to a classification problem later.\n\nset.seed(123)  # for reproducibility\n\n# Simulating the dataset\nn &lt;- 10000  # number of observations\ndata &lt;- tibble(\n  age = runif(n, 18, 70),  # random ages between 18 and 70\n  income = runif(n, 30000, 100000),  # random income between 30k and 100k\n)\n\n# Create a non-linear relationship for the target variable\nsim_data &lt;- data %&gt;%\n  mutate(\n    purchase_likelihood = 0.5 * sin(age / 10) + 0.3 * log(income / 30000) + rnorm(n, 0, 0.2),\n    purchase = as.factor(ifelse(purchase_likelihood &gt; 0.5, 1, 0))  # binary target variable\n  )\n\nAnother way:\n\nmake_data &lt;- function(n, base_std_dev = 1 / 2) {\n  tibble(x = runif(n, min = -2, max = 2)) %&gt;% # Ensuring x ranges between -2 and 2\n    mutate(\n      y = (x^4) + 2 * exp(-7 * (x - 0.3)^2),\n      y = y + rnorm(n, sd = base_std_dev * (1 + abs(x^3))) # Varying std_dev with x\n    )\n}\n\nn &lt;- 10000\nset.seed(8383)\nsim_data &lt;- make_data(n)\n\n\nsim_data %&gt;% \n  ggplot(aes(x, y)) + \n  geom_point(alpha = 1 / 10)\n\n\n\n\n\n\n\n\n\n# This is from the tidymodels example here: https://www.tidymodels.org/learn/models/conformal-regression/\n# \n\nmake_variable_data &lt;- function(n, std_dev = 1 / 5) {\n  tibble(x = runif(n, min = -1)) %&gt;%\n    mutate(\n      y = (x^3) + 2 * exp(-6 * (x - 0.3)^2),\n      y = y + rnorm(n, sd = std_dev * abs(x))\n    )\n}\n\nn &lt;- 10000\nset.seed(8383)\nsim_data &lt;- make_variable_data(n)\n\nsim_data %&gt;% \n  ggplot(aes(x, y)) + \n  geom_point(alpha = 1 / 10)\n\n\n\n\n\n\n\n\nCool, let’s see how well a few simple models do.\nBut first, we must split it up:\nThis is important for common model performance checking, but also because we’ll need the validation set for conformal prediction later.\n\nsplit &lt;- rsample::initial_validation_split(sim_data)\ntrain &lt;- rsample::training(split)\ntest &lt;- rsample::testing(split)\nval &lt;- rsample::validation(split)\n\n\nlm_mod &lt;- lm(y ~ x, data = train)\nspline_mod &lt;- gam(y ~ s(x), data = train)\n\ncompare_performance(lm_mod, spline_mod)\n\n# Comparison of Model Performance Indices\n\nName       | Model |   AIC (weights) |  AICc (weights) |   BIC (weights) |    R2 |  RMSE | Sigma | R2 (adj.)\n------------------------------------------------------------------------------------------------------------\nlm_mod     |    lm |  9495.3 (&lt;.001) |  9495.3 (&lt;.001) |  9515.4 (&lt;.001) | 0.642 | 0.534 | 0.534 |     0.642\nspline_mod |   gam | -8746.0 (&gt;.999) | -8745.9 (&gt;.999) | -8672.6 (&gt;.999) | 0.983 | 0.117 | 0.117 |          \n\n\n\ntest_preds &lt;- test %&gt;% \n  mutate(lm_predictions = predict(lm_mod, newdata = .),\n         spline_predictions = predict(spline_mod, newdata = .))\n\nlm_metrics &lt;- test_preds %&gt;% \n  yardstick::metrics(truth = y, estimate = lm_predictions) %&gt;% \n  mutate(type = 'lm_metrics')\nspline_metrics &lt;- test_preds %&gt;% \n  yardstick::metrics(truth = y, estimate = spline_predictions) %&gt;% \n  mutate(type = 'spline_metrics')\n\nperf &lt;- bind_rows(lm_metrics, spline_metrics)\nperf\n\n# A tibble: 6 × 4\n  .metric .estimator .estimate type          \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;         \n1 rmse    standard      0.548  lm_metrics    \n2 rsq     standard      0.624  lm_metrics    \n3 mae     standard      0.444  lm_metrics    \n4 rmse    standard      0.118  spline_metrics\n5 rsq     standard      0.983  spline_metrics\n6 mae     standard      0.0822 spline_metrics\n\n\nCool, let’s see how this looks over the range of test truth and estimates.\n\nlm_plot &lt;- test_preds %&gt;% \n  ggplot(aes(x = x, y = lm_predictions)) + \n  geom_point() +\n  theme_minimal()\n\nspline_plot &lt;- test_preds %&gt;% \n  ggplot(aes(x = x, y = spline_predictions)) + \n  geom_point() +\n  theme_minimal()\n\ngrid.arrange(lm_plot, spline_plot, ncol = 2)\n\n\n\n\n\n\n\n\nOk, let’s build out the basic steps for conformal prediction:\n\nData Split: We’ve already done this earlier. The validation set, or calibration as some people call it, is important in this process. Make sure you have that.\nModel Training: Train a model. In this case, we’ll train both the linear model and the GAM.\nConformity Measure: We’ll need to define a conformity measure. This is a function that essentially assigns a numerical score to each instance, which reflects how well the estimate ‘conforms’ to the other instances in the validation set. Typically this is just the ‘distance’ or error between your model’s prediction and the validation set. However, this could be anything for your specific problem.\nConformity Score: This is the computation of error given the measure in step 3.\nPrediction: For any new instance that you’d like to predict, you use your model to run prediction and then we’ll move to compute a conformity score.\nConfidence Level Determination: Given your new instances conformity score, we’ll now compare it to the distribution of scores derived from the validation set to determine the confidence level.\nOutput Prediction Intervals: We can then generate a prediction interval.\n\nIn its simplest form, conformal prediction is a statistical technique that provides a measure of certainty for machine learning model predictions by generating prediction intervals, using the conformity of new instances to a calibration set to indicate how likely these predictions are to be accurate. This method leverages the distribution of conformity scores from a calibration set to assess the reliability of predictions for new data.\nBecause we’ve already trained our two models, we now just need to leverage the validation set.\n\nset.seed(123)\nlm_validation_scores &lt;- val %&gt;%\n  mutate(\n    prediction = predict(lm_mod, .),\n    error = abs(y - prediction)\n  )\n\nquant &lt;- quantile(lm_validation_scores$error, probs = 0.95)\n\nlm_validation_scores %&gt;% \n  ggplot(aes(x = error)) + \n  geom_histogram() + \n  geom_vline(xintercept = quant)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nspline_validation_scores &lt;- val %&gt;%\n  mutate(\n    prediction = predict(spline_mod, .),\n    error = abs(y - prediction)\n  )\n\nquant &lt;- quantile(spline_validation_scores$error, probs = 0.95)\n\nspline_validation_scores %&gt;% \n  ggplot(aes(x = error)) + \n  geom_histogram() + \n  geom_vline(xintercept = quant)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nSplit Conformal Intervals\nNow we can create a function that uses all the information we have to generate conformal intervals.\n\n# Function to calculate the conformal prediction interval for new data without y values\nconformal_interval &lt;- function(new_data, model, calibration_set, alpha = 0.95) {\n  # Predict y values for the calibration set\n  validation_scores &lt;- calibration_set %&gt;%\n    mutate(\n      prediction = predict(model, .),\n      error = abs(y - prediction)\n    )\n  \n  error_quantile &lt;- quantile(validation_scores$error, probs = 0.95)\n  print(error_quantile)\n  # # Predict y values for the new data\n  \n  new_preds &lt;- new_data %&gt;% \n    mutate(predictions = predict(model, .),\n           .lower = predictions - error_quantile,\n           .upper = predictions + error_quantile\n           )\n}\n\nlm_result &lt;- conformal_interval(new_data = test, model = lm_mod, calibration_set = val, alpha = 0.05)\n\n      95% \n0.9635453 \n\nlm_result\n\n# A tibble: 2,000 × 5\n         x       y predictions   .lower .upper\n     &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1  0.197   1.89        0.960  -0.00344  1.92 \n 2 -0.265   0.164       0.389  -0.575    1.35 \n 3 -0.523  -0.0874      0.0699 -0.894    1.03 \n 4  0.845   1.10        1.76    0.799    2.73 \n 5  0.0130  1.22        0.733  -0.231    1.70 \n 6 -0.819  -0.679      -0.297  -1.26     0.667\n 7 -0.630  -0.261      -0.0630 -1.03     0.901\n 8 -0.560  -0.0740      0.0243 -0.939    0.988\n 9 -0.314   0.166       0.329  -0.635    1.29 \n10 -0.0195  1.08        0.693  -0.271    1.66 \n# ℹ 1,990 more rows\n\n\nNot sure this viz is useful:\n\nlm_result %&gt;% \n  slice_sample(n = 100) %&gt;% \n  ggplot(aes(x = y, y = predictions)) + \n  geom_point() + \n  geom_errorbar(aes(ymin = .lower, ymax = .upper), width = 0.1)\n\nslice_sample: removed 1,900 rows (95%), 100 rows remaining\n\n\n\n\n\n\n\n\n\n\nlm_result %&gt;%\n  ggplot(aes(x = x, y = predictions)) +\n  geom_point(color = \"black\", size = 0.5) + # Adjust point color and size\n  geom_point(aes(x = x, y = y), color = 'green', size = 0.5) +\n  geom_errorbar(aes(ymin = .lower, ymax = .upper),\n    width = 0.2, # Adjust the width of the error bars\n    color = \"grey\", # Change color of error bars\n    alpha = 0.2\n  ) + # Adjust transparency\n  ggtitle(\"Age vs Predictions with Conformal Prediction Intervals\") + # Add a title\n  labs(x = \"Age\", y = \"Predicted Value\") + # Label the axes\n  theme_minimal() + # Apply a minimal theme\n  theme(\n    plot.title = element_text(hjust = 0.5), # Center the title\n    text = element_text(size = 12)\n  ) # Adjust text size\n\n\n\n\n\n\n\n\nAs you can see, the relationship between age and the prediction is actually non-linear (as designed/simulated, in green), however, what is also obvious is that the error across the range of age is also not normal and changes as a function of the predictor.\nSo, given the modeled linear effect, this seem plausible.\nLet’s take a look at the spline model.\n\nspline_result &lt;- conformal_interval(new_data = test, model = spline_mod, calibration_set = val, alpha = 0.05)\n\n      95% \n0.2540535 \n\n\nNot sure this is useful:\n\nspline_result %&gt;% \n  # slice_sample(n = 100) %&gt;% \n  ggplot(aes(x = y, y = predictions)) + \n  geom_point() + \n  geom_errorbar(aes(ymin = .lower, ymax = .upper), width = 0.1)\n\n\n\n\n\n\n\n\n\nspline_result %&gt;%\n  slice_sample(n = 1000) %&gt;% \n  ggplot(aes(x = x, y = predictions)) +\n  geom_point(color = \"black\", size = 0.5) + # Adjust point color and size\n  geom_point(aes(x = x, y = y), color = 'green', size = 0.5) +\n  geom_errorbar(aes(ymin = .lower, ymax = .upper),\n    width = 0.05, # Adjust the width of the error bars\n    color = \"grey\", # Change color of error bars\n    alpha = 0.2\n  ) + # Adjust transparency\n  ggtitle(\"X vs Predictions with Conformal Prediction Intervals\") + # Add a title\n  labs(x = \"Age\", y = \"Predicted Value\") + # Label the axes\n  theme_minimal() + # Apply a minimal theme\n  theme(\n    plot.title = element_text(hjust = 0.5), # Center the title\n    text = element_text(size = 12)\n  ) # Adjust text size\n\nslice_sample: removed 1,000 rows (50%), 1,000 rows remaining\n\n\n\n\n\n\n\n\n\n\nspline_result %&gt;% \n  slice_sample(n = 2000) %&gt;% \n  ggplot(aes(x)) +\n  geom_point(aes(y = predictions), color = 'blue') +\n  geom_point(aes(y = y), alpha = 1/10) + \n  geom_ribbon(aes(ymin = .lower, ymax = .upper), \n              col = \"#D95F02\", linewidth = 3 / 4, fill = NA)\n\nslice_sample: no rows removed\n\n\n\n\n\n\n\n\n\nAlso plausible. But in truth, there is nothing super fancy about estimating error from the 95% quantile perspective. In other words, we assume that all the error for each point that could be predicted might be found in this span of error if we did this forever. Of course, this is a frequentist perspective. While I personally dont always ascribe to this perspective, I think it works fine. The only thing that is of issue here is that we obviously know there are some prediction values we can predict better than others simply given the data arrangement and how some multivariate combinations of predictors arrive at a stronger prediction.\n\n\nConformalized Quantile Regression\n\nconformal_quantile_intervals &lt;- function(train_set, calib_set, new_data, alpha = 0.05) {\n  # Fit the quantile regression tree model\n  train_x &lt;- train_set %&gt;% select(-y)\n  train_y &lt;- train_set %&gt;% select(y) %&gt;% pull()\n  \n  qrf_model &lt;- quantregForest(x = train_x, \n                              y = train_y,\n                              nthreads = 8)\n  \n  # Determine the lower and upper quantiles\n  quantiles &lt;- c(alpha/2, 1 - alpha/2)\n  \n  # Predict quantiles on the calibration set\n  calib_pred &lt;- predict(qrf_model, calib_set[, -ncol(calib_set)], \n                        type = \"quantiles\", quantiles = quantiles)\n  \n  # Compute conformity scores\n  lower_bound &lt;- calib_pred[, 1]\n  upper_bound &lt;- calib_pred[, 2]\n  calib_actual &lt;- calib_set[, ncol(calib_set)]\n  conformity_scores &lt;- pmax(lower_bound - calib_actual,\n                            calib_actual - upper_bound)\n\n  # Calculate the quantile of the conformity scores\n  q_alpha &lt;- quantile(conformity_scores$y, probs = 1 - alpha)\n\n  # Predict quantiles for new data\n  new_pred &lt;- predict(qrf_model, new_data, type = \"quantiles\",\n                      quantiles = quantiles)\n\n  # Adjust prediction intervals based on conformity scores\n  intervals &lt;- cbind(new_pred[, 1] - q_alpha, new_pred[, 2] + q_alpha)\n  colnames(intervals) &lt;- c(\"quant_lower\", \"quant_upper\")\n\n  return(intervals)\n}\n\nconformal_quant_intervals &lt;- conformal_quantile_intervals(\n  train_set = train, \n  calib_set = val,\n  new_data = test,\n  alpha = 0.05\n)\n\nLet’s visualize this! For the predictions, we’ll just use the point predictions generated from the spline model… as it was the best looking.\n\nconf_quant_int &lt;- bind_cols(spline_result, conformal_quant_intervals)\n\nconf_quant_int %&gt;%\n  slice_sample(n = 1000) %&gt;% \n  ggplot(aes(x = x, y = predictions)) +\n  geom_point(color = \"black\", size = 0.5) + # Adjust point color and size\n  geom_point(aes(x = x, y = y), color = 'green', size = 0.5) +\n  geom_errorbar(aes(ymin = quant_lower, ymax = quant_upper),\n    width = 0.05, # Adjust the width of the error bars\n    color = \"grey\", # Change color of error bars\n    alpha = 0.2\n  ) + # Adjust transparency\n  ggtitle(\"X vs Predictions with Conformal Prediction Intervals\") + # Add a title\n  labs(x = \"x\", y = \"Predicted Value\") + # Label the axes\n  theme_minimal() + # Apply a minimal theme\n  theme(\n    plot.title = element_text(hjust = 0.5), # Center the title\n    text = element_text(size = 12)\n  ) # Adjust text size\n\nslice_sample: removed 1,000 rows (50%), 1,000 rows remaining\n\n\n\n\n\n\n\n\n\nAlternative visualization\n\nconf_quant_int %&gt;% \n  # slice_sample(n = 500) %&gt;% \n  ggplot(aes(x)) +\n  geom_point(aes(y = predictions), color = 'blue') +\n  geom_point(aes(y = y), alpha = 1/10) + \n  geom_ribbon(aes(ymin = quant_lower, ymax = quant_upper), \n              col = \"#D95F02\", linewidth = 3 / 4, fill = NA)\n\n\n\n\n\n\n\n\nThis is a work in progress…\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{l._debusk-lane2024,\n  author = {L. DeBusk-Lane, M.},\n  title = {Conformal {Prediction}},\n  date = {2024-06-30},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nL. DeBusk-Lane, M. 2024. “Conformal Prediction.” June 30,\n2024."
  },
  {
    "objectID": "research/cb_md_2018/cb_md_2018.html",
    "href": "research/cb_md_2018/cb_md_2018.html",
    "title": "Motivation belief profiles in science: Links to classroom goal structures and achievement",
    "section": "",
    "text": "PDF\n\n\nUsing a person-centered approach, this study examined science motivation belief (achievement goals and self- efficacy) profiles among middle school students (N = 1443). Three profiles were identified across grades: con- fidently mastery, high all, and low confidence/low mastery. For grades 6 (n = 520) and 7 (n = 307), a fourth profile, indifferent, and for grade 8 (n = 613), two new profiles, low all and performance-driven, were identified at the end of the school year. Results from latent transition analyses showed relatively stable profile membership; 42–89% of students remained in the same profile between time points. Classroom goal structures predicted profile membership and were aligned to students’ personal goal endorsements. Evidence was also found for the asso- ciation between profile and science achievement. Confidently mastery students demonstrated the highest science achievement, whereas performance was lower for all other profiles, with low confidence/low mastery students generally demonstrating the lowest science achievement."
  },
  {
    "objectID": "research/cb_md_kh_fz_2018/cb_md_kh_fz_2018.html",
    "href": "research/cb_md_kh_fz_2018/cb_md_kh_fz_2018.html",
    "title": "Opportunities to Participate (OtP) in Science: Examining Differences Longitudinally and Across Socioeconomically Diverse Schools.",
    "section": "",
    "text": "PDF\n\n\nThe purpose of this study was to develop and validate a survey of opportunities to participate (OtP) in science that will allow educators and researchers to closely approximate the types of learning opportunities students have in science classrooms. Additionally, we examined whether and how opportunity gaps in science learning may exist across schools with different socio- economic levels. The OtP in science survey consists of four dimensions that include acquiring foundational knowledge, planning an investigation, conducting an investigation, and using evidence to communicate findings. A total of 1214 middle school students across 8 diverse school districts completed the survey. Tests of reliability, construct validity, measurement invariance, and external validity were conducted using data collected at the beginning and end of the school year. Results showed evidence that the OtP in science survey scores were internally reliable, invariant across school socioeconomic groups across and time points (i.e., lacking systematic biases in responses by group or time point), and externally valid. Given that scores from the survey were reliable and valid indicators of the four dimensions of interest, structural invariance tests were conducted to examine possible differences in OtP in science across schools from high, middle, and low socioeconomic backgrounds. Findings demonstrate specific ways opportunity gaps to learn science manifest in lower income schools. We discuss the implications of these gaps for science instruction, professional development, policy, and diverse students’ interest and achievement in science, and propose several lines of future study."
  },
  {
    "objectID": "research/cb_mldl_LID_2019/cb_mldl_LID_2019.html",
    "href": "research/cb_mldl_LID_2019/cb_mldl_LID_2019.html",
    "title": "Middle school engagement profiles: Implications for motivation and achievement in science",
    "section": "",
    "text": "PDF\n\n\n“Teachers play a critical role in successfully implementing science education reforms in the United States to provide\nhigh-quality science learning opportunities to all students. However, the differentiated ways in which\nteachers make decisions about their science teaching are not well understood. This study takes a person-centered approach by applying latent profile analysis to examine how cognitive (pedagogical content knowledge) and motivational (instructional goal orientations, self-efficacy beliefs, and reform values) characteristics combine to form science teacher profiles in middle school. Predictors of profile membership (bachelor’s degree, school %FRL) and both teacher (science instructional practices) and\nstudent (science achievement, engagement, and self-efficacy) outcomes related to the teacher profiles were also\nexamined. Five science teacher profiles were identified (severely discouraged but reform oriented, discouraged but reform oriented, conventional, confident and mastery oriented, and confident with multiple goal approaches) that represented unique configurations of cognitive and motivation characteristics. Additionally,\nfindings showed that the teacher profiles were significantly related to three dimensions of science instructional practice including communication, discourse, and reasoning. Finally, the teacher profiles were significantly related to student science achievement and motivational outcomes. Implications for differentiated approaches to teacher professional learning and supports for science instruction are discussed.”"
  },
  {
    "objectID": "research/jr_cb_md_2019/jr_cb_md_2019.html",
    "href": "research/jr_cb_md_2019/jr_cb_md_2019.html",
    "title": "Implicit Theories, Working Memory, and Cognitive Load: Impacts on Creative Thinking",
    "section": "",
    "text": "PDF\n\n\nCreative thinking shares many characteristics with traditional complex tasks. We investigated whether implicit theories of creativity would affect creative thinking in a way similar to the impact of implicit theories of intelligence on academic tasks. We altered participants’ theories of creativity to be either more incremental or more entity-like. We also examined the impact of working memory (WM) and cognitive load on creative thinking. Cognitive load fully mediated the relationship between implicit theories and creative thinking, with more incremental beliefs linked to lower cognitive load. In addition, cognitive load partially mediated the relationship between WM and creative thinking. Our results support prior research showing that creative thinking draws on cognitive mechanisms similar to those utilized by other complex tasks, but the impact of implicit theories on creative thinking differs from their effect on traditional academic tasks."
  },
  {
    "objectID": "research/cb_kh_md_2019/cb_kh_md_2019.html",
    "href": "research/cb_kh_md_2019/cb_kh_md_2019.html",
    "title": "Profiles of middle school science teachers: Accounting for cognitive and motivational characteristics",
    "section": "",
    "text": "PDF\n\n\nTeachers play a critical role in successfully implementing science education reforms in the United States to provide\nhigh-quality science learning opportunities to all stu- dents. However, the differentiated ways in which\nteachers make decisions about their science teaching are not well understood. This study takes a person-centered approach by applying latent profile analysis to examine how cognitive (pedagogical content knowledge) and motivational (instructional goal orientations, self-efficacy beliefs, and reform values) characteristics combine to form science teacher profiles in middle school. Predictors of profile membership (bachelor’s degree, school %FRL) and both teacher (science instructional practices) and\nstudent (science achievement, engagement, and self-effi- cacy) outcomes related to the teacher profiles were also\nexamined. Five science teacher profiles were identified (severely discouraged but reform oriented, discouraged but reform oriented, conventional, confident and mastery oriented, and confident with multiple goal approaches) that represented unique configurations of cognitive and motivation characteristics. Additionally,\nfindings showed that the teacher profiles were signifi- cantly related to three dimensions of science instruc- tional practice including communication, discourse, and reasoning. Finally, the teacher profiles were significantly related to student science achievement and motivational outcomes. Implications for differentiated approaches to teacher professional learning and supports for science instruction are discussed."
  },
  {
    "objectID": "research/sz_ee_js_km_md_2017/sz_ee_js_km_md_2017.html",
    "href": "research/sz_ee_js_km_md_2017/sz_ee_js_km_md_2017.html",
    "title": "Student Experiences With Writing: Taking the Temperature of the Classroom",
    "section": "",
    "text": "PDF\n\n\n“Students’ literacy experiences and beliefs can have profound effects on their motivation, engagement, and learning. The authors explore tools that teachers can use to better understand students’ writing experiences and beliefs.”"
  },
  {
    "objectID": "research/ee_sz_md_2017/ee_sz_md_2017.html",
    "href": "research/ee_sz_md_2017/ee_sz_md_2017.html",
    "title": "Clarifying an Elusive Construct: a Systematic Review of Writing Attitudes",
    "section": "",
    "text": "PDF\n\n\nAlthough research recognizes that student attitudes toward writing have the poten- tial to influence a variety of writing outcomes, there is no consensus as to what writing attitude signifies. Further, disparities between conceptualizations of writing attitude make the extant literature difficult to reconcile. In the present study, we systematically review writing attitude research published between 1990 and 2017. Our search procedure and quality analysis led to the retention of 46 articles examining the writing attitudes of students and teachers. Relatively few studies (n = 10) provided an explicit definition of writing attitudes. Further, although the authors of many studies (n = 16) conceptualized writing attitude as including a measure of liking/disliking writing, there was considerable variability in both conceptualization and operationalization throughout the literature, with some studies including measures of self- efficacy, perceived value, and other related constructs. Student writing attitudes were measured in a majority of the included studies (n = 33), and teacher writing attitudes were measured in substantially fewer studies (n = 6). Based on the findings of this review, we offer suggestions for researchers making inferences from studies of writing attitudes. Themes of the reviewed literature and implications for future research are also discussed."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nImplicit Theories, Working Memory, and Cognitive Load: Impacts on Creative Thinking\n\n\n\nCreativity\n\n\nCognitive Load\n\n\nImplicit Theories\n\n\nIntelligence\n\n\n\n\nJan 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfiles of middle school science teachers: Accounting for cognitive and motivational characteristics\n\n\n\nMotivation\n\n\nLPA\n\n\n\n\nJan 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMiddle school engagement profiles: Implications for motivation and achievement in science\n\n\n\nMotivation\n\n\nLPA\n\n\n\n\nJan 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotivation belief profiles in science: Links to classroom goal structures and achievement\n\n\n\nMotivation\n\n\nLPA\n\n\n\n\nAug 4, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpportunities to Participate (OtP) in Science: Examining Differences Longitudinally and Across Socioeconomically Diverse Schools.\n\n\n\nMotivation\n\n\nSEM\n\n\nMeasurement Invariance\n\n\n\n\nJan 1, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClarifying an Elusive Construct: a Systematic Review of Writing Attitudes\n\n\n\nMotivation\n\n\n\n\nJan 1, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudent Experiences With Writing: Taking the Temperature of the Classroom\n\n\n\nMotivation\n\n\n\n\nJan 1, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/siu/siu_001.html",
    "href": "posts/siu/siu_001.html",
    "title": "Stuff I Use 001: Sentence Embeddings for Classification",
    "section": "",
    "text": "I often have a column of text responses that need to be classified. Essentially, this involves a zero-shot approach where I use a sentence transformer to generate embeddings for each response. I do the same for each label used in the classification. By calculating a similarity metric between each row and label, often cosine similarity, we can determine which embeddings (vectors representing sentences in lexical space) are most closely related to the labels.\n\n\n\n\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(tidyverse, here, pins, janitor, readxl,\n               reticulate, gt)\n\n\n\n\n\nsource(here('src', 'embed_process.R'))\nuse_condaenv(condaenv = 'embed', required = TRUE)\nsource_python(here('src', 'embed.py'))\n\nA few notes: The use_condaenv is a pre-established conda environment that matches the required libraries/packages needed in your sourced py file.\n\n\n\n\nThis function is saved within the earlier sourced R script, embed_process.R.\nIn all there are three functions here. The overall management function, and two internals that compute cosign similarity and another that situates the matrices to compute the similarity scores on a row by row basis.\nInputs:\n•   cats: Data frame containing the categories with their respective labels.\n•   input_data: Data frame containing the input data for which cosine similarity will be calculated.\n•   min_sim: Minimum similarity threshold (though not used directly in the provided function).\n•   target_verbatim: The column name in input_data containing the text data that will be used to generate embeddings.\n\nembedding_cosign &lt;- function(cats, input_data, target_verbatim) {\n  cats_emb &lt;- add_embeddings_to_dataframe(cats, 'label')\n  test_emb &lt;- add_embeddings_to_dataframe(input_data, target_verbatim)\n  \n  compute_cosine_similarity &lt;- function(vec1, vec2) {\n    sum(vec1 * vec2) / (sqrt(sum(vec1^2)) * sqrt(sum(vec2^2)))\n  }\n\n  compare_cats_to_utterances &lt;- function(cats_emb, data_emb) {\n    # Extract embeddings into matrices\n    cats_matrix &lt;- as.matrix(cats_emb |&gt; select(starts_with('embedding')))\n    data_matrix &lt;- as.matrix(data_emb |&gt; select(starts_with('embedding')))\n\n    # Compute cosine similarity\n    similarity_scores &lt;- map_df(1:nrow(data_matrix), function(i) {\n      map_dfc(1:nrow(cats_matrix), function(j) {\n        score &lt;- compute_cosine_similarity(data_matrix[i,], cats_matrix[j,])\n        col_name &lt;- cats_emb[j, 1] # Direct use of the category label\n        return(setNames(list(score), col_name))\n      })\n    })\n\n    # Combine similarity scores with original utterance data (excluding embeddings)\n    result_df &lt;- bind_cols(data_emb |&gt; select(-starts_with('embedding')), similarity_scores)\n\n    return(result_df)\n  }\n  \n  result &lt;- compare_cats_to_utterances(\n    cats_emb = cats_emb,\n    data_emb = test_emb\n  ) \n}\n\nAs mentioned earlier, you’ll need that conda environment to get these libraries going.\nThis function is very simple. Input any dataframe and the column you want to generate embedding for. It outputs the same dataframe and the embedding columns. In this case, I’m using the gte-base model. You can check it out here to see how it compares to other text embedding models: https://huggingface.co/thenlper/gte-base\n\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\n\ndef add_embeddings_to_dataframe(df, column_name):\n    # Load the sentence transformer model\n    model = SentenceTransformer('thenlper/gte-base')\n    \n    # Ensure the specified column exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n    \n    # Generate embeddings for the specified column.\n    # The output is a list of lists (each inner list is an embedding vector for a sentence).\n    embeddings = model.encode(df[column_name].to_list(), convert_to_tensor=False, show_progress_bar=True)\n    \n    # Convert embeddings to a DataFrame.\n    embeddings_df = pd.DataFrame(embeddings)\n    \n    # Rename the columns to indicate they are embedding dimensions.\n    embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n    \n    # Concatenate the original DataFrame with the embeddings DataFrame.\n    result_df = pd.concat([df, embeddings_df], axis=1)\n    \n    return result_df"
  },
  {
    "objectID": "posts/siu/siu_001.html#setup",
    "href": "posts/siu/siu_001.html#setup",
    "title": "Stuff I Use 001: Sentence Embeddings for Classification",
    "section": "",
    "text": "if (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(tidyverse, here, pins, janitor, readxl,\n               reticulate, gt)\n\n\n\n\n\nsource(here('src', 'embed_process.R'))\nuse_condaenv(condaenv = 'embed', required = TRUE)\nsource_python(here('src', 'embed.py'))\n\nA few notes: The use_condaenv is a pre-established conda environment that matches the required libraries/packages needed in your sourced py file."
  },
  {
    "objectID": "posts/siu/siu_001.html#review-key-functions",
    "href": "posts/siu/siu_001.html#review-key-functions",
    "title": "Stuff I Use 001: Sentence Embeddings for Classification",
    "section": "",
    "text": "This function is saved within the earlier sourced R script, embed_process.R.\nIn all there are three functions here. The overall management function, and two internals that compute cosign similarity and another that situates the matrices to compute the similarity scores on a row by row basis.\nInputs:\n•   cats: Data frame containing the categories with their respective labels.\n•   input_data: Data frame containing the input data for which cosine similarity will be calculated.\n•   min_sim: Minimum similarity threshold (though not used directly in the provided function).\n•   target_verbatim: The column name in input_data containing the text data that will be used to generate embeddings.\n\nembedding_cosign &lt;- function(cats, input_data, target_verbatim) {\n  cats_emb &lt;- add_embeddings_to_dataframe(cats, 'label')\n  test_emb &lt;- add_embeddings_to_dataframe(input_data, target_verbatim)\n  \n  compute_cosine_similarity &lt;- function(vec1, vec2) {\n    sum(vec1 * vec2) / (sqrt(sum(vec1^2)) * sqrt(sum(vec2^2)))\n  }\n\n  compare_cats_to_utterances &lt;- function(cats_emb, data_emb) {\n    # Extract embeddings into matrices\n    cats_matrix &lt;- as.matrix(cats_emb |&gt; select(starts_with('embedding')))\n    data_matrix &lt;- as.matrix(data_emb |&gt; select(starts_with('embedding')))\n\n    # Compute cosine similarity\n    similarity_scores &lt;- map_df(1:nrow(data_matrix), function(i) {\n      map_dfc(1:nrow(cats_matrix), function(j) {\n        score &lt;- compute_cosine_similarity(data_matrix[i,], cats_matrix[j,])\n        col_name &lt;- cats_emb[j, 1] # Direct use of the category label\n        return(setNames(list(score), col_name))\n      })\n    })\n\n    # Combine similarity scores with original utterance data (excluding embeddings)\n    result_df &lt;- bind_cols(data_emb |&gt; select(-starts_with('embedding')), similarity_scores)\n\n    return(result_df)\n  }\n  \n  result &lt;- compare_cats_to_utterances(\n    cats_emb = cats_emb,\n    data_emb = test_emb\n  ) \n}\n\nAs mentioned earlier, you’ll need that conda environment to get these libraries going.\nThis function is very simple. Input any dataframe and the column you want to generate embedding for. It outputs the same dataframe and the embedding columns. In this case, I’m using the gte-base model. You can check it out here to see how it compares to other text embedding models: https://huggingface.co/thenlper/gte-base\n\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\n\ndef add_embeddings_to_dataframe(df, column_name):\n    # Load the sentence transformer model\n    model = SentenceTransformer('thenlper/gte-base')\n    \n    # Ensure the specified column exists in the DataFrame\n    if column_name not in df.columns:\n        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n    \n    # Generate embeddings for the specified column.\n    # The output is a list of lists (each inner list is an embedding vector for a sentence).\n    embeddings = model.encode(df[column_name].to_list(), convert_to_tensor=False, show_progress_bar=True)\n    \n    # Convert embeddings to a DataFrame.\n    embeddings_df = pd.DataFrame(embeddings)\n    \n    # Rename the columns to indicate they are embedding dimensions.\n    embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n    \n    # Concatenate the original DataFrame with the embeddings DataFrame.\n    result_df = pd.concat([df, embeddings_df], axis=1)\n    \n    return result_df"
  },
  {
    "objectID": "posts/groupwalk/groupwalk.html",
    "href": "posts/groupwalk/groupwalk.html",
    "title": "group_walk",
    "section": "",
    "text": "I ran across this little gem at work today trying to build a function to easily iterate out a series of excel files (.xlsx) that needed to be generated from an identifier column in a larger dataset. Lets take a look.\n\nlibrary(tidyverse)\nlibrary(writexl)\n\nLet’s grab some data!!!\n\ndata(iris)\n\nLet’s take a look.\n\niris %&gt;%\n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\n\n\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\n\n\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\n\n\n\n\nYou’ll notice that aside from the 4 numeric species attributes (Sepal & Petal length and width), there is an identification/classification variable (actually a factor variable) that denotes which Species each flower is.\nFor this demonstration, I’d like to create three seperate ‘.xlsx’ files simply based on this identification. What would be helpful, in the end, is to have each file named after this identification.\nThankfully, the {dplyr} package has made this super simple.\n\niris %&gt;%\n  group_by(Species) %&gt;% # Group by the variable for which you wish to iterate over to create individual files from.\n  group_walk(~ write_xlsx(.x, paste0(\"iris_\", .y$Species, \".xlsx\")), keep = TRUE)\n\n\ngroup_by\nTo walk through this a bit, you’ll notice a simple group_by function that serves to identify which column we wish to not only group our data by, but the one which we’d like to iterate over to make individual files from.\n\n\ngroup_walk (group_map)\nNext, the group_walk function, which is an extension of the group_map series (more info here) that mimics many purrr functions, except through a series of groups… not just a list, df columsn, or some type of nest.\nIdentical to the other walk functions that are used for their ‘side effects’ (think output, not what it returns… ), the group_walk function silently returns the .x argument. We’re interested in what it does, not the data it may produce. Afterall, I just want the output of the function. I plan to dive into this in a future map post in the future… it can be confusing. Nicely, the group_walk function also includes an option to keep the grouping variable through the keep = option that retains the variable in each .x.\nTo wrap this up, the paste0 function serves to meet the second argument requirement for write_xlsx. If you’re not familiar with paste0/paste, it simply combindes all arguments together. In this case, it is simply taking the string prefix “iris_,” each Species, and “.xlsx” and concatenates them.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{l._debusk-lane2020,\n  author = {L. DeBusk-Lane, M.},\n  title = {Group\\_walk},\n  date = {2020-02-25},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nL. DeBusk-Lane, M. 2020. “Group_walk.” February 25, 2020."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nConformal Prediction\n\n\n\nR\n\n\nConformal\n\n\n\n\nJun 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStuff I Use 001: Sentence Embeddings for Classification\n\n\n\nR\n\n\nPython\n\n\nTransformers\n\n\nNLP\n\n\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation: Part 0\n\n\n\nCode\n\n\nSimulation\n\n\nR\n\n\n\n\nNov 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup_walk\n\n\n\nCode\n\n\nR\n\n\n\n\nFeb 25, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  }
]